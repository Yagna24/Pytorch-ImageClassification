{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transfer-convnext2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XA-1D1ZKe8d3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np \n",
        "import PIL \n",
        "import os\n",
        "from PIL import Image\n",
        "import json \n",
        "import sys \n",
        " \n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision import datasets \n",
        "from torch.optim import lr_scheduler\n",
        "\n",
        "import matplotlib.pyplot as plt \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm \n",
        "\n",
        "from timm import create_model "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FcfHkRD3fLBT",
        "outputId": "eb985b2a-27d4-443d-fe90-a76f89d972b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting timm\n",
            "  Downloading timm-0.5.4-py3-none-any.whl (431 kB)\n",
            "\u001b[?25l\r\u001b[K     |▊                               | 10 kB 20.2 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 20 kB 22.4 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 30 kB 26.1 MB/s eta 0:00:01\r\u001b[K     |███                             | 40 kB 13.3 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 51 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 61 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 71 kB 11.3 MB/s eta 0:00:01\r\u001b[K     |██████                          | 81 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 92 kB 13.5 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 102 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 112 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 122 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 133 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 143 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 153 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 163 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 174 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 184 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 194 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 204 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 215 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 225 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 235 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 245 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 256 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 266 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 276 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 286 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 296 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 307 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 317 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 327 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 337 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 348 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 358 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 368 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 378 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 389 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 399 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 409 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 419 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 430 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 431 kB 12.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm) (1.10.0+cu111)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.11.1+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm) (3.10.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (1.21.5)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n",
            "Installing collected packages: timm\n",
            "Successfully installed timm-0.5.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n",
        "%cd /content\n",
        "!mkdir drive\n",
        "%cd drive\n",
        "!mkdir MyDrive\n",
        "%cd ..\n",
        "%cd ..\n",
        "!google-drive-ocamlfuse /content/drive/MyDrive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHpMAa5ysWBO",
        "outputId": "9bf78996-08aa-4e83-c237-0f183849c143"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E: Package 'python-software-properties' has no installation candidate\n",
            "Selecting previously unselected package google-drive-ocamlfuse.\n",
            "(Reading database ... 155320 files and directories currently installed.)\n",
            "Preparing to unpack .../google-drive-ocamlfuse_0.7.27-0ubuntu1~ubuntu18.04.1_amd64.deb ...\n",
            "Unpacking google-drive-ocamlfuse (0.7.27-0ubuntu1~ubuntu18.04.1) ...\n",
            "Setting up google-drive-ocamlfuse (0.7.27-0ubuntu1~ubuntu18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n",
            "/content\n",
            "/content/drive\n",
            "/content\n",
            "/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.transforms.transforms import Resize\n",
        "# Data augmentation and normalization for training\n",
        "# Just normalization for validation\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.Resize(255),\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "                               \n",
        "        transforms.Resize(255),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n"
      ],
      "metadata": {
        "id": "p77YYStDsfXv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = '/content/drive/MyDrive/hymenoptera_data'\n",
        "\n",
        "\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
        "                                          data_transforms[x])\n",
        "                  for x in ['train', 'val']}\n",
        "\n",
        "\n",
        "\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
        "                                             shuffle=True, num_workers=4)\n",
        "              for x in ['train', 'val']}\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NM1kUy4sso_R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aec6eb1c-0d37-4c6c-91d8-e9ab60196fd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
        "class_names = image_datasets['train'].classes"
      ],
      "metadata": {
        "id": "jCoGnqNQtdPy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CChA4NUHtMaE",
        "outputId": "31d3685d-9724-4eb4-8d44-329d255c4727"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ants', 'bees']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def imshow(inp, title=None):\n",
        "#     \"\"\"Imshow for Tensor.\"\"\"\n",
        "#     inp = inp.numpy().transpose((1, 2, 0))\n",
        "#     mean = np.array([0.485, 0.456, 0.406])\n",
        "#     std = np.array([0.229, 0.224, 0.225])\n",
        "#     inp = std * inp + mean\n",
        "#     inp = np.clip(inp, 0, 1)\n",
        "#     plt.imshow(inp)\n",
        "#     if title is not None:\n",
        "#         plt.title(title)\n",
        "#     plt.pause(0.001)  # pause a bit so that plots are updated\n",
        "\n",
        "\n",
        "# # Get a batch of training data\n",
        "# inputs, classes = next(iter(dataloaders['train']))\n",
        "\n",
        "# # Make a grid from batch\n",
        "# out = torchvision.utils.make_grid(inputs)\n",
        "\n",
        "# imshow(out, title=[class_names[x] for x in classes])"
      ],
      "metadata": {
        "id": "7msWkKaWuMxb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"convnext_large\"\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(\"device = \", device)\n",
        "model = create_model(model_name, pretrained=True).to(device)"
      ],
      "metadata": {
        "id": "i4TJ_k-Dylcj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch.nn as nn \n",
        "\n",
        "# classifier = nn.Sequential(\n",
        "#   nn.Linear(in_features=2048, out_features=1024),\n",
        "#   nn.ReLU(),\n",
        "#   nn.Dropout(p=0.4),\n",
        "#   nn.Linear(in_features=1024, out_features=64),\n",
        "#   nn.LogSoftmax(dim=1)  \n",
        "# )"
      ],
      "metadata": {
        "id": "B1WAptDMnI9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import copy \n",
        "\n",
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ],
      "metadata": {
        "id": "B45QvjtctNYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def visualize_model(model, num_images=6):\n",
        "#     was_training = model.training\n",
        "#     model.eval()\n",
        "#     images_so_far = 0\n",
        "#     fig = plt.figure()\n",
        "\n",
        "#     with torch.no_grad():\n",
        "#         for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
        "#             inputs = inputs.to(device)\n",
        "#             labels = labels.to(device)\n",
        "\n",
        "#             outputs = model(inputs)\n",
        "#             _, preds = torch.max(outputs, 1)\n",
        "\n",
        "#             for j in range(inputs.size()[0]):\n",
        "#                 images_so_far += 1\n",
        "#                 ax = plt.subplot(num_images//2, 2, images_so_far)\n",
        "#                 ax.axis('off')\n",
        "#                 ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
        "#                 imshow(inputs.cpu().data[j])\n",
        "\n",
        "#                 if images_so_far == num_images:\n",
        "#                     model.train(mode=was_training)\n",
        "#                     return\n",
        "#         model.train(mode=was_training)"
      ],
      "metadata": {
        "id": "CH6rGDhvvCDh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn \n",
        "import torch.optim as optim \n",
        "# model.num_features = nn.Linear(model.num_features, 2)"
      ],
      "metadata": {
        "id": "F0BsQxJmuQdl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(resnet.parameters(), lr = 0.0001, momentum  = 0.7 )\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
        "\n"
      ],
      "metadata": {
        "id": "A9rxVLBjEXq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import models \n",
        "\n",
        "model = models.resnet50(pretrained=True).to(device)\n",
        "    \n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False   \n",
        "    \n",
        "model.fc = nn.Sequential(\n",
        "               nn.Linear(2048, 128),\n",
        "               nn.ReLU(inplace=True),\n",
        "               nn.Linear(128, 2)).to(device)\n"
      ],
      "metadata": {
        "id": "EWQEZrQDKpZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "incept = models.inception_v3(pretrained=True).to(device)\n",
        "\n",
        "# shufflenet = models.ShuffleNetV2(pretrained = True ) \n",
        "for param in incept.parameters() : \n",
        "  param.requires_grad = False \n",
        "\n",
        "incept.fc = nn.Sequential(\n",
        "               nn.Linear(2048, 128),\n",
        "               nn.ReLU(inplace=True),\n",
        "               nn.Linear(128, 2)).to(device)\n",
        "\n"
      ],
      "metadata": {
        "id": "BfDmjfmKOtyF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "squeezenet = models.squeezenet1_1(pretrained =  True ).to(device)\n",
        "\n",
        "for param in squeezenet.parameters() : \n",
        "  param.requires_grad = \n",
        "\n",
        "squeezenet.fc = nn.Sequential(\n",
        "               nn.Linear(2048, 128),\n",
        "               nn.ReLU(inplace=True),\n",
        "               nn.Linear(128, 2)).to(device)\n"
      ],
      "metadata": {
        "id": "bZp3TFMYOvMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer1 = optim.Adam(squeezenet.fc.parameters())\n"
      ],
      "metadata": {
        "id": "1iydzVSjQmUn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = train_model(squeezenet, criterion, optimizer1, exp_lr_scheduler, num_epochs=70 )"
      ],
      "metadata": {
        "id": "kO3EUgLUEe5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict() , '/content/model_resnet.pt')"
      ],
      "metadata": {
        "id": "42603g5W1IIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/model_resnet.pt /content/drive/MyDrive/pytorch_models"
      ],
      "metadata": {
        "id": "vATodN2YEjWz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.load('model4.pt')\n"
      ],
      "metadata": {
        "id": "CM1YCaVj0U75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()"
      ],
      "metadata": {
        "id": "nhQF4HUqYp_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_model(model)"
      ],
      "metadata": {
        "id": "2Kd0YAShCxUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install timm"
      ],
      "metadata": {
        "id": "x2CVpkHmfEeS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "\n",
        "class MyEnsemble(nn.Module):\n",
        "\n",
        "    def __init__(self, modelA, modelB, input):\n",
        "        super(MyEnsemble, self).__init__()\n",
        "        self.modelA = modelA\n",
        "        self.modelB = modelB\n",
        "        # self.modelC = modelC\n",
        "\n",
        "        self.fc1 = nn.Linear(input, 16)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out1 = self.modelA(x)\n",
        "        out2 = self.modelB(x)\n",
        "        # out3 = self.modelC(x)\n",
        "\n",
        "        out = out1 + out2 \n",
        "\n",
        "        x = self.fc1(out)\n",
        "        return torch.softmax(x, dim=1)"
      ],
      "metadata": {
        "id": "80vKepdsxDZD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelA = torch.load('/content/gdrive/MyDrive/pytorch_models/model1.pt')\n",
        "modelB = torch.load('/content/gdrive/MyDrive/pytorch_models/model2.pt')\n",
        "# modelC = torch.load('/content/gdrive/MyDrive/pytorch_models/model3.pt')"
      ],
      "metadata": {
        "id": "YkFZhXJnemi2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "V7ldu9CAe9vS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelA.parameters"
      ],
      "metadata": {
        "id": "jU8tn5QkhVjz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_final  = MyEnsemble(modelA, modelB,  1000 )"
      ],
      "metadata": {
        "id": "ydQxyxgDfsFW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_final = model_final.to(device)"
      ],
      "metadata": {
        "id": "EEU-PD4xf3MX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim \n",
        "optimizer = optim.Adam(model_final.parameters(),lr=0.003)\n",
        "# turn this off\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)"
      ],
      "metadata": {
        "id": "6R1zp5V1f6hy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_final = train_model(model_final, criterion, optimizer, exp_lr_scheduler,num_epochs=7)"
      ],
      "metadata": {
        "id": "4Zk0zVIBgB4M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "sFmnefkSiBVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "fWF7SSM2ghd0",
        "outputId": "b0229777-6c20-484a-cf0b-99156212b730"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'|===========================================================================|\\n|                  PyTorch CUDA memory summary, device ID 0                 |\\n|---------------------------------------------------------------------------|\\n|            CUDA OOMs: 5            |        cudaMalloc retries: 5         |\\n|===========================================================================|\\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\\n|---------------------------------------------------------------------------|\\n| Allocated memory      |   10208 MB |   10208 MB |   13035 MB |    2826 MB |\\n|       from large pool |   10119 MB |   10119 MB |   12916 MB |    2796 MB |\\n|       from small pool |      89 MB |      89 MB |     119 MB |      29 MB |\\n|---------------------------------------------------------------------------|\\n| Active memory         |   10208 MB |   10208 MB |   13035 MB |    2826 MB |\\n|       from large pool |   10119 MB |   10119 MB |   12916 MB |    2796 MB |\\n|       from small pool |      89 MB |      89 MB |     119 MB |      29 MB |\\n|---------------------------------------------------------------------------|\\n| GPU reserved memory   |   10904 MB |   10904 MB |   10904 MB |       0 B  |\\n|       from large pool |   10814 MB |   10814 MB |   10814 MB |       0 B  |\\n|       from small pool |      90 MB |      90 MB |      90 MB |       0 B  |\\n|---------------------------------------------------------------------------|\\n| Non-releasable memory |  711683 KB |  728937 KB |    7056 MB |    6361 MB |\\n|       from large pool |  711152 KB |  727168 KB |    6927 MB |    6233 MB |\\n|       from small pool |     531 KB |   12550 KB |     128 MB |     128 MB |\\n|---------------------------------------------------------------------------|\\n| Allocations           |    3894    |    3895    |    8015    |    4121    |\\n|       from large pool |    1263    |    1263    |    1611    |     348    |\\n|       from small pool |    2631    |    2632    |    6404    |    3773    |\\n|---------------------------------------------------------------------------|\\n| Active allocs         |    3894    |    3895    |    8015    |    4121    |\\n|       from large pool |    1263    |    1263    |    1611    |     348    |\\n|       from small pool |    2631    |    2632    |    6404    |    3773    |\\n|---------------------------------------------------------------------------|\\n| GPU reserved segments |     534    |     534    |     534    |       0    |\\n|       from large pool |     489    |     489    |     489    |       0    |\\n|       from small pool |      45    |      45    |      45    |       0    |\\n|---------------------------------------------------------------------------|\\n| Non-releasable allocs |     382    |     385    |    3413    |    3031    |\\n|       from large pool |     376    |     377    |     732    |     356    |\\n|       from small pool |       6    |      15    |    2681    |    2675    |\\n|---------------------------------------------------------------------------|\\n| Oversize allocations  |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Oversize GPU segments |       0    |       0    |       0    |       0    |\\n|===========================================================================|\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "q3mKaRqol9LE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}